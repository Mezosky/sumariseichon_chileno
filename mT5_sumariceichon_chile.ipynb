{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29a546ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import cuda\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import os\n",
    "\n",
    "# Importing the mT5 modules from huggingface/transformers\n",
    "from transformers import T5Tokenizer, MT5Model, MT5Config, MT5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba74da63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loggger\n",
    "logging.basicConfig(\n",
    "    filename = 'finetunning.log', \n",
    "    encoding = 'utf-8', \n",
    "    level    = logging.INFO, \n",
    "    format   = '%(asctime)s :  %(message)s', \n",
    "    datefmt  = '%m/%d/%Y %I:%M:%S %p'\n",
    ")\n",
    "\n",
    "# set up logging to console\n",
    "console = logging.StreamHandler()\n",
    "console.setLevel(logging.DEBUG)\n",
    "# set a format which is simpler for console use\n",
    "formatter = logging.Formatter(\n",
    "    '%(asctime)s %(message)s',\n",
    "    datefmt  = '%m/%d/%Y %I:%M:%S %p'\n",
    ")\n",
    "console.setFormatter(formatter)\n",
    "# add the handler to the root logger\n",
    "logging.getLogger('').addHandler(console)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9feb16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params={\n",
    "    \"MODEL\":\"google/mt5-small\",     # model_type: mt5-base/mt5-large\n",
    "    \"TRAIN_BATCH_SIZE\":8,           # training batch size\n",
    "    \"VALID_BATCH_SIZE\":8,           # validation batch size\n",
    "    \"TRAIN_EPOCHS\":2,              # number of training epochs\n",
    "    \"VAL_EPOCHS\":1,                # number of validation epochs\n",
    "    \"LEARNING_RATE\":2e-4,           # learning rate\n",
    "    \"MAX_SOURCE_TEXT_LENGTH\":512,   # max length of source text\n",
    "    \"MAX_TARGET_TEXT_LENGTH\":258,   # max length of target text\n",
    "    \"SEED\": 42                      # set seed for reproducibility \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c99a34a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds and deterministic pytorch for reproducibility\n",
    "torch.manual_seed(model_params[\"SEED\"])\n",
    "np.random.seed(model_params[\"SEED\"]) \n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "181af844",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummaryDataSet(Dataset):\n",
    "    \"\"\"\n",
    "    Dataloader to Finetune a mT5 model focused in a summarization task.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        dataframe: pd.DataFrame, \n",
    "        tokenizer: T5Tokenizer, \n",
    "        source_len: int, \n",
    "        target_len: int, \n",
    "        source_text: str, \n",
    "        target_text: str,\n",
    "    ) -> None:\n",
    "        \n",
    "        self.tokenizer   = tokenizer\n",
    "        self.source_len  = source_len\n",
    "        self.summ_len    = target_len\n",
    "        self.target_text = dataframe[target_text]\n",
    "        self.source_text = dataframe[source_text]\n",
    "    \n",
    "    def __getitem__(\n",
    "        self, index: int\n",
    "    ) -> dict[str: torch.Tensor]:\n",
    "        \n",
    "        source_text = str(self.source_text[index])\n",
    "        target_text = str(self.target_text[index])\n",
    "\n",
    "        #cleaning data so as to ensure data is in string type\n",
    "        source_text = ' '.join(source_text.split())\n",
    "        target_text = ' '.join(target_text.split())\n",
    "\n",
    "        source = self.tokenizer.batch_encode_plus(\n",
    "            [source_text], \n",
    "            max_length        = self.source_len, \n",
    "            pad_to_max_length = True, \n",
    "            truncation        = True, \n",
    "            padding           = \"max_length\", \n",
    "            return_tensors    = 'pt'\n",
    "        )\n",
    "        target = self.tokenizer.batch_encode_plus(\n",
    "            [target_text], \n",
    "            max_length        = self.summ_len, \n",
    "            pad_to_max_length = True, \n",
    "            truncation        = True, \n",
    "            padding           = \"max_length\", \n",
    "            return_tensors    = 'pt'\n",
    "        )\n",
    "\n",
    "        source_ids  = source['input_ids'].squeeze()\n",
    "        source_mask = source['attention_mask'].squeeze()\n",
    "        target_ids  = target['input_ids'].squeeze()\n",
    "        target_mask = target['attention_mask'].squeeze()\n",
    "\n",
    "        return {\n",
    "            'source_ids': source_ids.to(dtype=torch.long), \n",
    "            'source_mask': source_mask.to(dtype=torch.long), \n",
    "            'target_ids': target_ids.to(dtype=torch.long),\n",
    "            'target_ids_y': target_ids.to(dtype=torch.long)\n",
    "        }\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.target_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b76f72e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: MT5ForConditionalGeneration, \n",
    "    tokenizer: T5Tokenizer, \n",
    "    epoch: int, \n",
    "    loader: SummaryDataSet, \n",
    "    optimizer: torch.optim, \n",
    "    device: str = 'cuda' if cuda.is_available() else 'cpu'\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Function to be called for training with the parameters passed from main function\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    model.train()\n",
    "    for _, data in enumerate(loader, 0):\n",
    "    \n",
    "        y     = data['target_ids'].to(device, dtype = torch.long)\n",
    "        y_ids = y[:, :-1].contiguous()\n",
    "        \n",
    "        lm_labels = y[:, 1:].clone().detach()\n",
    "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "        \n",
    "        ids  = data['source_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids         = ids, \n",
    "            attention_mask    = mask, \n",
    "            decoder_input_ids = y_ids, \n",
    "            labels            = lm_labels\n",
    "        )\n",
    "        loss = outputs[0]\n",
    "        \n",
    "        if _%10==0:\n",
    "            logger.info(f'Epoch: {epoch+1} | Loss: {str(round(float(outputs[0]), 3))}')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "827a6512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(\n",
    "    model: MT5ForConditionalGeneration,\n",
    "    tokenizer: T5Tokenizer,\n",
    "    epoch: int, \n",
    "    loader: SummaryDataSet,\n",
    "    device: str = 'cuda' if cuda.is_available() else 'cpu'\n",
    ") -> (list, list):    \n",
    "    \"\"\"\n",
    "    Function to evaluate model for predictions\n",
    "\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for it, data in enumerate(loader, 0):\n",
    "            y    = data['target_ids'].to(device, dtype = torch.long)\n",
    "            ids  = data['source_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "            generated_ids = model.generate(\n",
    "              input_ids          = ids,\n",
    "              attention_mask     = mask, \n",
    "              max_length         = 150, \n",
    "              num_beams          = 2,\n",
    "              repetition_penalty = 2.5, \n",
    "              length_penalty     = 1.0, \n",
    "              early_stopping     = True\n",
    "            )\n",
    "\n",
    "            preds  = [\n",
    "                tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) \n",
    "                for g in generated_ids\n",
    "            ]\n",
    "            target = [\n",
    "                tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True) \n",
    "                for t in y\n",
    "            ]\n",
    "\n",
    "            if _%10==0:\n",
    "                logger.info(f'Completed {it}')\n",
    "\n",
    "            predictions.extend(preds)\n",
    "            actuals.extend(target)\n",
    "            \n",
    "    return predictions, actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b50f3618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mT5Trainer(\n",
    "    dataframe: pd.DataFrame, \n",
    "    source_text: str, \n",
    "    target_text: str, \n",
    "    model_params: dict, \n",
    "    output_dir: str =\"/data/imeza/text_datasets/outputs_mT5/\",\n",
    "    device: str = 'cuda' if cuda.is_available() else 'cpu'\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    mT5 trainer\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # logging\n",
    "    logger.info(f\"\"\"[Model]: Loading {model_params[\"MODEL\"]}...\\n\"\"\")\n",
    "\n",
    "    # tokenzier for encoding the text\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_params[\"MODEL\"])\n",
    "\n",
    "    # Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary. \n",
    "    # Further this model is sent to device (GPU/TPU) for using the hardware.\n",
    "    model = MT5ForConditionalGeneration.from_pretrained(model_params[\"MODEL\"])\n",
    "    model = model.to(device)\n",
    "\n",
    "    # logging\n",
    "    logger.info(f\"[Data]: Reading data...\\n\")\n",
    "\n",
    "    # Importing the raw dataset\n",
    "    dataframe = dataframe[[source_text,target_text]]\n",
    "\n",
    "\n",
    "    # Creation of Dataset and Dataloader\n",
    "    # Defining the train size. So 80% of the data will be used for training and the rest for validation. \n",
    "    train_size = 0.8\n",
    "    train_dataset=dataframe.sample(frac=train_size,random_state = model_params[\"SEED\"])\n",
    "    val_dataset=dataframe.drop(train_dataset.index).reset_index(drop=True)\n",
    "    train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "    logger.info(f\"FULL Dataset : {dataframe.shape}\")\n",
    "    logger.info(f\"TRAIN Dataset: {train_dataset.shape}\")\n",
    "    logger.info(f\"TEST Dataset : {val_dataset.shape}\\n\")\n",
    "\n",
    "    # Creating the Training and Validation dataset for further creation of Dataloader\n",
    "    training_set = SummaryDataSet(\n",
    "        train_dataset, \n",
    "        tokenizer, \n",
    "        model_params[\"MAX_SOURCE_TEXT_LENGTH\"], \n",
    "        model_params[\"MAX_TARGET_TEXT_LENGTH\"], \n",
    "        source_text, target_text\n",
    "    )\n",
    "    val_set      = SummaryDataSet(\n",
    "        val_dataset, tokenizer, \n",
    "        model_params[\"MAX_SOURCE_TEXT_LENGTH\"], \n",
    "        model_params[\"MAX_TARGET_TEXT_LENGTH\"], \n",
    "        source_text, target_text\n",
    "    )\n",
    "\n",
    "\n",
    "    # Defining the parameters for creation of dataloaders\n",
    "    train_params = {\n",
    "      'batch_size': model_params[\"TRAIN_BATCH_SIZE\"],\n",
    "      'shuffle': True,\n",
    "      'num_workers': 0\n",
    "      }\n",
    "\n",
    "\n",
    "    val_params = {\n",
    "      'batch_size': model_params[\"VALID_BATCH_SIZE\"],\n",
    "      'shuffle': False,\n",
    "      'num_workers': 0\n",
    "      }\n",
    "\n",
    "\n",
    "    # Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
    "    training_loader = DataLoader(training_set, **train_params)\n",
    "    val_loader      = DataLoader(val_set, **val_params)\n",
    "\n",
    "\n",
    "    # Defining the optimizer that will be used to tune the weights of the network in the training session. \n",
    "    optimizer = torch.optim.Adam(params =  model.parameters(), lr=model_params[\"LEARNING_RATE\"])\n",
    "\n",
    "\n",
    "    # Training loop\n",
    "    logger.info(f'[Initiating Fine Tuning]...\\n')\n",
    "\n",
    "    for epoch in range(model_params[\"TRAIN_EPOCHS\"]):\n",
    "        train(model, tokenizer, epoch, training_loader, optimizer, device)\n",
    "\n",
    "    logger.info(f\"[Saving Model]...\\n\")\n",
    "    #Saving the model after training\n",
    "    path = os.path.join(output_dir, \"model_files\")\n",
    "    model.save_pretrained(path)\n",
    "    tokenizer.save_pretrained(path)\n",
    "\n",
    "\n",
    "    # evaluating test dataset\n",
    "    logger.info(f\"[Initiating Validation]...\\n\")\n",
    "    for epoch in range(model_params[\"VAL_EPOCHS\"]):\n",
    "        predictions, actuals = validate(model, tokenizer, epoch, val_loader, device)\n",
    "        final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n",
    "        final_df.to_csv(os.path.join(output_dir,'predictions.csv'))\n",
    "\n",
    "    logger.info(f\"[Validation Completed.]\\n\")\n",
    "    logger.info(f\"[Model] Model saved @ {os.path.join(output_dir, 'model_files')}\\n\")\n",
    "    logger.info(f\"[Validation] Generation on Validation data saved @ {os.path.join(output_dir,'predictions.csv')}\\n\")\n",
    "    logger.info(f\"[Logs] Logs saved @ {os.path.join(output_dir,'logs.txt')}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32586c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"/data/imeza/text_datasets/data_summarization_with_title.parquet\")\n",
    "df[\"text\"] = \"summarize: \"+df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd844037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aprobado histórico acuerdo de pérdidas y daños...</td>\n",
       "      <td>La conferencia del clima de la ONU (COP27) apr...</td>\n",
       "      <td>summarize: Las negociaciones fueron accidentad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Covid-19: Minsal reportó 3.543 casos nuevos y ...</td>\n",
       "      <td>La autoridad sanitaria indicó que hay 13.917 c...</td>\n",
       "      <td>summarize: El Ministerio de Salud informó 3.54...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zapallar aprueba ordenanza que restringe tráns...</td>\n",
       "      <td>El concejo de la comuna dio luz verde a la med...</td>\n",
       "      <td>summarize: El Concejo Municipal de Zapallar ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Inglaterra golea a Irán y se confirma como fav...</td>\n",
       "      <td>La selección inglesa dio un golpe de autoridad...</td>\n",
       "      <td>summarize: Arrancó el segundo día del Mundial ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dirigente de los camioneros destacó acercamien...</td>\n",
       "      <td>Este lunes, los dirigentes de la Confederación...</td>\n",
       "      <td>summarize: Los dirigentes de los transportista...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Aprobado histórico acuerdo de pérdidas y daños...   \n",
       "1  Covid-19: Minsal reportó 3.543 casos nuevos y ...   \n",
       "2  Zapallar aprueba ordenanza que restringe tráns...   \n",
       "3  Inglaterra golea a Irán y se confirma como fav...   \n",
       "4  Dirigente de los camioneros destacó acercamien...   \n",
       "\n",
       "                                           headlines  \\\n",
       "0  La conferencia del clima de la ONU (COP27) apr...   \n",
       "1  La autoridad sanitaria indicó que hay 13.917 c...   \n",
       "2  El concejo de la comuna dio luz verde a la med...   \n",
       "3  La selección inglesa dio un golpe de autoridad...   \n",
       "4  Este lunes, los dirigentes de la Confederación...   \n",
       "\n",
       "                                                text  \n",
       "0  summarize: Las negociaciones fueron accidentad...  \n",
       "1  summarize: El Ministerio de Salud informó 3.54...  \n",
       "2  summarize: El Concejo Municipal de Zapallar ap...  \n",
       "3  summarize: Arrancó el segundo día del Mundial ...  \n",
       "4  summarize: Los dirigentes de los transportista...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09750e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/08/2022 05:34:07 PM [Model]: Loading google/mt5-small...\n",
      "\n",
      "12/08/2022 05:34:13 PM [Data]: Reading data...\n",
      "\n",
      "12/08/2022 05:34:13 PM FULL Dataset : (170430, 2)\n",
      "12/08/2022 05:34:13 PM TRAIN Dataset: (136344, 2)\n",
      "12/08/2022 05:34:13 PM TEST Dataset : (34086, 2)\n",
      "\n",
      "12/08/2022 05:34:13 PM [Initiating Fine Tuning]...\n",
      "\n",
      "12/08/2022 05:34:16 PM Epoch: 0 | Loss: 18.892\n",
      "12/08/2022 05:34:18 PM Epoch: 0 | Loss: 11.192\n",
      "12/08/2022 05:34:21 PM Epoch: 0 | Loss: 8.539\n",
      "12/08/2022 05:34:23 PM Epoch: 0 | Loss: 8.227\n",
      "12/08/2022 05:34:26 PM Epoch: 0 | Loss: 7.359\n",
      "12/08/2022 05:34:28 PM Epoch: 0 | Loss: 6.891\n",
      "12/08/2022 05:34:31 PM Epoch: 0 | Loss: 6.495\n",
      "12/08/2022 05:34:34 PM Epoch: 0 | Loss: 6.53\n",
      "12/08/2022 05:34:36 PM Epoch: 0 | Loss: 6.261\n",
      "12/08/2022 05:34:39 PM Epoch: 0 | Loss: 5.816\n",
      "12/08/2022 05:34:41 PM Epoch: 0 | Loss: 6.343\n",
      "12/08/2022 05:34:44 PM Epoch: 0 | Loss: 5.773\n",
      "12/08/2022 05:34:46 PM Epoch: 0 | Loss: 5.977\n",
      "12/08/2022 05:34:49 PM Epoch: 0 | Loss: 5.702\n",
      "12/08/2022 05:34:51 PM Epoch: 0 | Loss: 6.464\n",
      "12/08/2022 05:34:54 PM Epoch: 0 | Loss: 5.249\n",
      "12/08/2022 05:34:56 PM Epoch: 0 | Loss: 5.847\n",
      "12/08/2022 05:34:59 PM Epoch: 0 | Loss: 5.206\n",
      "12/08/2022 05:35:02 PM Epoch: 0 | Loss: 5.241\n",
      "12/08/2022 05:35:04 PM Epoch: 0 | Loss: 6.045\n",
      "12/08/2022 05:35:07 PM Epoch: 0 | Loss: 5.654\n",
      "12/08/2022 05:35:09 PM Epoch: 0 | Loss: 6.175\n",
      "12/08/2022 05:35:12 PM Epoch: 0 | Loss: 4.993\n",
      "12/08/2022 05:35:14 PM Epoch: 0 | Loss: 5.795\n",
      "12/08/2022 05:35:17 PM Epoch: 0 | Loss: 5.374\n",
      "12/08/2022 05:35:19 PM Epoch: 0 | Loss: 4.518\n",
      "12/08/2022 05:35:22 PM Epoch: 0 | Loss: 4.682\n",
      "12/08/2022 05:35:25 PM Epoch: 0 | Loss: 4.485\n",
      "12/08/2022 05:35:27 PM Epoch: 0 | Loss: 5.063\n",
      "12/08/2022 05:35:30 PM Epoch: 0 | Loss: 5.274\n",
      "12/08/2022 05:35:32 PM Epoch: 0 | Loss: 5.04\n",
      "12/08/2022 05:35:35 PM Epoch: 0 | Loss: 4.559\n",
      "12/08/2022 05:35:37 PM Epoch: 0 | Loss: 4.514\n",
      "12/08/2022 05:35:40 PM Epoch: 0 | Loss: 4.437\n",
      "12/08/2022 05:35:42 PM Epoch: 0 | Loss: 4.178\n",
      "12/08/2022 05:35:45 PM Epoch: 0 | Loss: 4.38\n",
      "12/08/2022 05:35:47 PM Epoch: 0 | Loss: 4.18\n",
      "12/08/2022 05:35:50 PM Epoch: 0 | Loss: 3.808\n",
      "12/08/2022 05:35:53 PM Epoch: 0 | Loss: 4.373\n",
      "12/08/2022 05:35:55 PM Epoch: 0 | Loss: 4.65\n",
      "12/08/2022 05:35:58 PM Epoch: 0 | Loss: 3.858\n",
      "12/08/2022 05:36:00 PM Epoch: 0 | Loss: 4.419\n",
      "12/08/2022 05:36:03 PM Epoch: 0 | Loss: 3.95\n",
      "12/08/2022 05:36:05 PM Epoch: 0 | Loss: 4.096\n",
      "12/08/2022 05:36:08 PM Epoch: 0 | Loss: 4.744\n",
      "12/08/2022 05:36:10 PM Epoch: 0 | Loss: 4.183\n",
      "12/08/2022 05:36:13 PM Epoch: 0 | Loss: 3.868\n",
      "12/08/2022 05:36:16 PM Epoch: 0 | Loss: 4.506\n",
      "12/08/2022 05:36:18 PM Epoch: 0 | Loss: 4.465\n",
      "12/08/2022 05:36:21 PM Epoch: 0 | Loss: 4.529\n",
      "12/08/2022 05:36:23 PM Epoch: 0 | Loss: 4.185\n",
      "12/08/2022 05:36:26 PM Epoch: 0 | Loss: 4.5\n",
      "12/08/2022 05:36:28 PM Epoch: 0 | Loss: 3.788\n",
      "12/08/2022 05:36:31 PM Epoch: 0 | Loss: 4.303\n",
      "12/08/2022 05:36:33 PM Epoch: 0 | Loss: 4.05\n",
      "12/08/2022 05:36:36 PM Epoch: 0 | Loss: 4.171\n",
      "12/08/2022 05:36:39 PM Epoch: 0 | Loss: 3.639\n",
      "12/08/2022 05:36:41 PM Epoch: 0 | Loss: 4.62\n",
      "12/08/2022 05:36:44 PM Epoch: 0 | Loss: 4.61\n",
      "12/08/2022 05:36:46 PM Epoch: 0 | Loss: 3.827\n",
      "12/08/2022 05:36:49 PM Epoch: 0 | Loss: 3.52\n",
      "12/08/2022 05:36:51 PM Epoch: 0 | Loss: 3.651\n",
      "12/08/2022 05:36:54 PM Epoch: 0 | Loss: 4.42\n",
      "12/08/2022 05:36:56 PM Epoch: 0 | Loss: 4.066\n",
      "12/08/2022 05:36:59 PM Epoch: 0 | Loss: 3.839\n",
      "12/08/2022 05:37:02 PM Epoch: 0 | Loss: 3.76\n",
      "12/08/2022 05:37:04 PM Epoch: 0 | Loss: 3.787\n",
      "12/08/2022 05:37:07 PM Epoch: 0 | Loss: 3.25\n",
      "12/08/2022 05:37:09 PM Epoch: 0 | Loss: 4.002\n",
      "12/08/2022 05:37:12 PM Epoch: 0 | Loss: 3.818\n",
      "12/08/2022 05:37:14 PM Epoch: 0 | Loss: 3.717\n",
      "12/08/2022 05:37:17 PM Epoch: 0 | Loss: 3.65\n",
      "12/08/2022 05:37:19 PM Epoch: 0 | Loss: 3.473\n",
      "12/08/2022 05:37:22 PM Epoch: 0 | Loss: 3.858\n",
      "12/08/2022 05:37:25 PM Epoch: 0 | Loss: 4.357\n",
      "12/08/2022 05:37:27 PM Epoch: 0 | Loss: 3.391\n",
      "12/08/2022 05:37:30 PM Epoch: 0 | Loss: 4.559\n",
      "12/08/2022 05:37:32 PM Epoch: 0 | Loss: 3.298\n",
      "12/08/2022 05:37:35 PM Epoch: 0 | Loss: 3.247\n",
      "12/08/2022 05:37:37 PM Epoch: 0 | Loss: 3.856\n",
      "12/08/2022 05:37:40 PM Epoch: 0 | Loss: 3.521\n",
      "12/08/2022 05:37:43 PM Epoch: 0 | Loss: 4.089\n",
      "12/08/2022 05:37:45 PM Epoch: 0 | Loss: 3.968\n",
      "12/08/2022 05:37:48 PM Epoch: 0 | Loss: 4.027\n",
      "12/08/2022 05:37:50 PM Epoch: 0 | Loss: 3.233\n",
      "12/08/2022 05:37:53 PM Epoch: 0 | Loss: 3.856\n",
      "12/08/2022 05:37:55 PM Epoch: 0 | Loss: 3.714\n",
      "12/08/2022 05:37:58 PM Epoch: 0 | Loss: 3.72\n",
      "12/08/2022 05:38:00 PM Epoch: 0 | Loss: 3.378\n",
      "12/08/2022 05:38:03 PM Epoch: 0 | Loss: 3.898\n",
      "12/08/2022 05:38:05 PM Epoch: 0 | Loss: 3.781\n",
      "12/08/2022 05:38:08 PM Epoch: 0 | Loss: 3.721\n",
      "12/08/2022 05:38:11 PM Epoch: 0 | Loss: 4.056\n",
      "12/08/2022 05:38:13 PM Epoch: 0 | Loss: 3.764\n",
      "12/08/2022 05:38:16 PM Epoch: 0 | Loss: 3.833\n",
      "12/08/2022 05:38:18 PM Epoch: 0 | Loss: 3.412\n",
      "12/08/2022 05:38:21 PM Epoch: 0 | Loss: 3.105\n",
      "12/08/2022 05:38:23 PM Epoch: 0 | Loss: 3.834\n",
      "12/08/2022 05:38:26 PM Epoch: 0 | Loss: 3.65\n",
      "12/08/2022 05:38:28 PM Epoch: 0 | Loss: 3.512\n",
      "12/08/2022 05:38:31 PM Epoch: 0 | Loss: 3.779\n",
      "12/08/2022 05:38:34 PM Epoch: 0 | Loss: 3.664\n",
      "12/08/2022 05:38:36 PM Epoch: 0 | Loss: 3.915\n",
      "12/08/2022 05:38:39 PM Epoch: 0 | Loss: 3.555\n",
      "12/08/2022 05:38:41 PM Epoch: 0 | Loss: 3.856\n",
      "12/08/2022 05:38:44 PM Epoch: 0 | Loss: 3.461\n",
      "12/08/2022 05:38:46 PM Epoch: 0 | Loss: 3.625\n",
      "12/08/2022 05:38:49 PM Epoch: 0 | Loss: 3.628\n",
      "12/08/2022 05:38:51 PM Epoch: 0 | Loss: 3.721\n",
      "12/08/2022 05:38:54 PM Epoch: 0 | Loss: 3.589\n",
      "12/08/2022 05:38:57 PM Epoch: 0 | Loss: 3.501\n",
      "12/08/2022 05:38:59 PM Epoch: 0 | Loss: 3.597\n",
      "12/08/2022 05:39:02 PM Epoch: 0 | Loss: 3.267\n",
      "12/08/2022 05:39:04 PM Epoch: 0 | Loss: 3.9\n",
      "12/08/2022 05:39:07 PM Epoch: 0 | Loss: 3.587\n",
      "12/08/2022 05:39:09 PM Epoch: 0 | Loss: 3.271\n",
      "12/08/2022 05:39:12 PM Epoch: 0 | Loss: 3.96\n",
      "12/08/2022 05:39:14 PM Epoch: 0 | Loss: 2.746\n",
      "12/08/2022 05:39:17 PM Epoch: 0 | Loss: 2.639\n",
      "12/08/2022 05:39:19 PM Epoch: 0 | Loss: 3.37\n",
      "12/08/2022 05:39:22 PM Epoch: 0 | Loss: 2.936\n",
      "12/08/2022 05:39:25 PM Epoch: 0 | Loss: 2.864\n",
      "12/08/2022 05:39:27 PM Epoch: 0 | Loss: 2.648\n",
      "12/08/2022 05:39:30 PM Epoch: 0 | Loss: 3.508\n",
      "12/08/2022 05:39:32 PM Epoch: 0 | Loss: 3.508\n",
      "12/08/2022 05:39:35 PM Epoch: 0 | Loss: 3.607\n",
      "12/08/2022 05:39:37 PM Epoch: 0 | Loss: 4.046\n",
      "12/08/2022 05:39:40 PM Epoch: 0 | Loss: 3.206\n",
      "12/08/2022 05:39:42 PM Epoch: 0 | Loss: 3.238\n",
      "12/08/2022 05:39:45 PM Epoch: 0 | Loss: 3.684\n",
      "12/08/2022 05:39:47 PM Epoch: 0 | Loss: 3.732\n",
      "12/08/2022 05:39:50 PM Epoch: 0 | Loss: 2.9\n",
      "12/08/2022 05:39:53 PM Epoch: 0 | Loss: 3.444\n",
      "12/08/2022 05:39:55 PM Epoch: 0 | Loss: 3.864\n",
      "12/08/2022 05:39:58 PM Epoch: 0 | Loss: 3.109\n",
      "12/08/2022 05:40:00 PM Epoch: 0 | Loss: 3.289\n",
      "12/08/2022 05:40:03 PM Epoch: 0 | Loss: 3.424\n",
      "12/08/2022 05:40:05 PM Epoch: 0 | Loss: 3.914\n",
      "12/08/2022 05:40:08 PM Epoch: 0 | Loss: 4.353\n",
      "12/08/2022 05:40:11 PM Epoch: 0 | Loss: 4.742\n",
      "12/08/2022 05:40:13 PM Epoch: 0 | Loss: 3.885\n",
      "12/08/2022 05:40:16 PM Epoch: 0 | Loss: 3.457\n",
      "12/08/2022 05:40:18 PM Epoch: 0 | Loss: 3.58\n",
      "12/08/2022 05:40:21 PM Epoch: 0 | Loss: 3.243\n",
      "12/08/2022 05:40:23 PM Epoch: 0 | Loss: 3.024\n",
      "12/08/2022 05:40:26 PM Epoch: 0 | Loss: 3.415\n",
      "12/08/2022 05:40:28 PM Epoch: 0 | Loss: 3.193\n",
      "12/08/2022 05:40:31 PM Epoch: 0 | Loss: 3.304\n",
      "12/08/2022 05:40:34 PM Epoch: 0 | Loss: 3.217\n",
      "12/08/2022 05:40:36 PM Epoch: 0 | Loss: 3.465\n",
      "12/08/2022 05:40:39 PM Epoch: 0 | Loss: 4.126\n",
      "12/08/2022 05:40:41 PM Epoch: 0 | Loss: 3.278\n",
      "12/08/2022 05:40:44 PM Epoch: 0 | Loss: 3.502\n",
      "12/08/2022 05:40:46 PM Epoch: 0 | Loss: 3.271\n",
      "12/08/2022 05:40:49 PM Epoch: 0 | Loss: 3.004\n",
      "12/08/2022 05:40:51 PM Epoch: 0 | Loss: 3.06\n",
      "12/08/2022 05:40:54 PM Epoch: 0 | Loss: 2.899\n",
      "12/08/2022 05:40:57 PM Epoch: 0 | Loss: 3.429\n",
      "12/08/2022 05:40:59 PM Epoch: 0 | Loss: 3.679\n",
      "12/08/2022 05:41:02 PM Epoch: 0 | Loss: 3.422\n",
      "12/08/2022 05:41:04 PM Epoch: 0 | Loss: 3.33\n",
      "12/08/2022 05:41:07 PM Epoch: 0 | Loss: 3.279\n",
      "12/08/2022 05:41:09 PM Epoch: 0 | Loss: 3.558\n",
      "12/08/2022 05:41:12 PM Epoch: 0 | Loss: 3.056\n",
      "12/08/2022 05:41:14 PM Epoch: 0 | Loss: 3.202\n",
      "12/08/2022 05:41:17 PM Epoch: 0 | Loss: 2.766\n",
      "12/08/2022 05:41:20 PM Epoch: 0 | Loss: 3.03\n",
      "12/08/2022 05:41:22 PM Epoch: 0 | Loss: 2.885\n",
      "12/08/2022 05:41:25 PM Epoch: 0 | Loss: 3.459\n",
      "12/08/2022 05:41:27 PM Epoch: 0 | Loss: 3.002\n",
      "12/08/2022 05:41:30 PM Epoch: 0 | Loss: 3.278\n",
      "12/08/2022 05:41:32 PM Epoch: 0 | Loss: 3.957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/08/2022 05:41:35 PM Epoch: 0 | Loss: 3.428\n",
      "12/08/2022 05:41:37 PM Epoch: 0 | Loss: 3.381\n",
      "12/08/2022 05:41:40 PM Epoch: 0 | Loss: 2.899\n",
      "12/08/2022 05:41:43 PM Epoch: 0 | Loss: 2.564\n",
      "12/08/2022 05:41:45 PM Epoch: 0 | Loss: 2.784\n",
      "12/08/2022 05:41:48 PM Epoch: 0 | Loss: 3.326\n",
      "12/08/2022 05:41:50 PM Epoch: 0 | Loss: 3.12\n",
      "12/08/2022 05:41:53 PM Epoch: 0 | Loss: 3.669\n",
      "12/08/2022 05:41:55 PM Epoch: 0 | Loss: 3.551\n",
      "12/08/2022 05:41:58 PM Epoch: 0 | Loss: 3.057\n",
      "12/08/2022 05:42:00 PM Epoch: 0 | Loss: 3.032\n",
      "12/08/2022 05:42:03 PM Epoch: 0 | Loss: 3.044\n",
      "12/08/2022 05:42:06 PM Epoch: 0 | Loss: 3.352\n",
      "12/08/2022 05:42:08 PM Epoch: 0 | Loss: 2.601\n",
      "12/08/2022 05:42:11 PM Epoch: 0 | Loss: 3.208\n",
      "12/08/2022 05:42:13 PM Epoch: 0 | Loss: 3.363\n",
      "12/08/2022 05:42:16 PM Epoch: 0 | Loss: 2.917\n",
      "12/08/2022 05:42:18 PM Epoch: 0 | Loss: 3.058\n",
      "12/08/2022 05:42:21 PM Epoch: 0 | Loss: 2.966\n",
      "12/08/2022 05:42:23 PM Epoch: 0 | Loss: 3.075\n",
      "12/08/2022 05:42:26 PM Epoch: 0 | Loss: 2.929\n",
      "12/08/2022 05:42:28 PM Epoch: 0 | Loss: 3.747\n",
      "12/08/2022 05:42:31 PM Epoch: 0 | Loss: 2.853\n",
      "12/08/2022 05:42:34 PM Epoch: 0 | Loss: 3.629\n",
      "12/08/2022 05:42:36 PM Epoch: 0 | Loss: 3.792\n",
      "12/08/2022 05:42:39 PM Epoch: 0 | Loss: 2.898\n",
      "12/08/2022 05:42:41 PM Epoch: 0 | Loss: 3.089\n",
      "12/08/2022 05:42:44 PM Epoch: 0 | Loss: 3.304\n",
      "12/08/2022 05:42:46 PM Epoch: 0 | Loss: 2.678\n",
      "12/08/2022 05:42:49 PM Epoch: 0 | Loss: 3.099\n",
      "12/08/2022 05:42:51 PM Epoch: 0 | Loss: 3.132\n",
      "12/08/2022 05:42:54 PM Epoch: 0 | Loss: 3.419\n",
      "12/08/2022 05:42:56 PM Epoch: 0 | Loss: 3.528\n",
      "12/08/2022 05:42:59 PM Epoch: 0 | Loss: 3.191\n",
      "12/08/2022 05:43:02 PM Epoch: 0 | Loss: 2.754\n",
      "12/08/2022 05:43:04 PM Epoch: 0 | Loss: 3.354\n",
      "12/08/2022 05:43:07 PM Epoch: 0 | Loss: 2.444\n",
      "12/08/2022 05:43:09 PM Epoch: 0 | Loss: 2.56\n",
      "12/08/2022 05:43:12 PM Epoch: 0 | Loss: 3.815\n",
      "12/08/2022 05:43:14 PM Epoch: 0 | Loss: 2.624\n",
      "12/08/2022 05:43:17 PM Epoch: 0 | Loss: 2.459\n",
      "12/08/2022 05:43:19 PM Epoch: 0 | Loss: 2.894\n",
      "12/08/2022 05:43:22 PM Epoch: 0 | Loss: 2.78\n",
      "12/08/2022 05:43:25 PM Epoch: 0 | Loss: 3.447\n",
      "12/08/2022 05:43:27 PM Epoch: 0 | Loss: 3.271\n",
      "12/08/2022 05:43:30 PM Epoch: 0 | Loss: 3.682\n",
      "12/08/2022 05:43:32 PM Epoch: 0 | Loss: 2.659\n",
      "12/08/2022 05:43:35 PM Epoch: 0 | Loss: 2.854\n",
      "12/08/2022 05:43:37 PM Epoch: 0 | Loss: 2.548\n",
      "12/08/2022 05:43:40 PM Epoch: 0 | Loss: 2.901\n",
      "12/08/2022 05:43:42 PM Epoch: 0 | Loss: 3.163\n",
      "12/08/2022 05:43:45 PM Epoch: 0 | Loss: 3.082\n",
      "12/08/2022 05:43:48 PM Epoch: 0 | Loss: 3.218\n",
      "12/08/2022 05:43:50 PM Epoch: 0 | Loss: 2.812\n",
      "12/08/2022 05:43:53 PM Epoch: 0 | Loss: 3.159\n",
      "12/08/2022 05:43:55 PM Epoch: 0 | Loss: 3.124\n",
      "12/08/2022 05:43:58 PM Epoch: 0 | Loss: 3.325\n",
      "12/08/2022 05:44:00 PM Epoch: 0 | Loss: 3.231\n",
      "12/08/2022 05:44:03 PM Epoch: 0 | Loss: 2.912\n",
      "12/08/2022 05:44:05 PM Epoch: 0 | Loss: 2.959\n",
      "12/08/2022 05:44:08 PM Epoch: 0 | Loss: 2.936\n",
      "12/08/2022 05:44:11 PM Epoch: 0 | Loss: 2.781\n",
      "12/08/2022 05:44:13 PM Epoch: 0 | Loss: 2.278\n",
      "12/08/2022 05:44:16 PM Epoch: 0 | Loss: 2.839\n",
      "12/08/2022 05:44:18 PM Epoch: 0 | Loss: 2.819\n",
      "12/08/2022 05:44:21 PM Epoch: 0 | Loss: 2.634\n",
      "12/08/2022 05:44:23 PM Epoch: 0 | Loss: 3.453\n",
      "12/08/2022 05:44:26 PM Epoch: 0 | Loss: 3.914\n",
      "12/08/2022 05:44:28 PM Epoch: 0 | Loss: 3.297\n",
      "12/08/2022 05:44:31 PM Epoch: 0 | Loss: 3.046\n",
      "12/08/2022 05:44:34 PM Epoch: 0 | Loss: 3.753\n",
      "12/08/2022 05:44:36 PM Epoch: 0 | Loss: 2.613\n",
      "12/08/2022 05:44:39 PM Epoch: 0 | Loss: 2.455\n",
      "12/08/2022 05:44:41 PM Epoch: 0 | Loss: 3.563\n",
      "12/08/2022 05:44:44 PM Epoch: 0 | Loss: 3.156\n",
      "12/08/2022 05:44:46 PM Epoch: 0 | Loss: 2.686\n",
      "12/08/2022 05:44:49 PM Epoch: 0 | Loss: 2.705\n",
      "12/08/2022 05:44:51 PM Epoch: 0 | Loss: 2.805\n",
      "12/08/2022 05:44:54 PM Epoch: 0 | Loss: 3.669\n",
      "12/08/2022 05:44:56 PM Epoch: 0 | Loss: 3.293\n",
      "12/08/2022 05:44:59 PM Epoch: 0 | Loss: 2.41\n",
      "12/08/2022 05:45:02 PM Epoch: 0 | Loss: 3.309\n",
      "12/08/2022 05:45:04 PM Epoch: 0 | Loss: 2.829\n",
      "12/08/2022 05:45:07 PM Epoch: 0 | Loss: 3.381\n",
      "12/08/2022 05:45:09 PM Epoch: 0 | Loss: 2.832\n",
      "12/08/2022 05:45:12 PM Epoch: 0 | Loss: 2.91\n",
      "12/08/2022 05:45:14 PM Epoch: 0 | Loss: 3.012\n",
      "12/08/2022 05:45:17 PM Epoch: 0 | Loss: 3.3\n",
      "12/08/2022 05:45:19 PM Epoch: 0 | Loss: 2.872\n",
      "12/08/2022 05:45:22 PM Epoch: 0 | Loss: 3.224\n",
      "12/08/2022 05:45:25 PM Epoch: 0 | Loss: 3.156\n",
      "12/08/2022 05:45:27 PM Epoch: 0 | Loss: 2.59\n",
      "12/08/2022 05:45:30 PM Epoch: 0 | Loss: 3.175\n",
      "12/08/2022 05:45:32 PM Epoch: 0 | Loss: 3.315\n",
      "12/08/2022 05:45:35 PM Epoch: 0 | Loss: 2.875\n",
      "12/08/2022 05:45:37 PM Epoch: 0 | Loss: 3.122\n",
      "12/08/2022 05:45:40 PM Epoch: 0 | Loss: 3.009\n",
      "12/08/2022 05:45:42 PM Epoch: 0 | Loss: 3.168\n",
      "12/08/2022 05:45:45 PM Epoch: 0 | Loss: 2.608\n",
      "12/08/2022 05:45:48 PM Epoch: 0 | Loss: 3.06\n",
      "12/08/2022 05:45:50 PM Epoch: 0 | Loss: 2.809\n",
      "12/08/2022 05:45:53 PM Epoch: 0 | Loss: 2.269\n",
      "12/08/2022 05:45:55 PM Epoch: 0 | Loss: 3.106\n",
      "12/08/2022 05:45:58 PM Epoch: 0 | Loss: 2.823\n",
      "12/08/2022 05:46:00 PM Epoch: 0 | Loss: 2.78\n",
      "12/08/2022 05:46:03 PM Epoch: 0 | Loss: 2.956\n",
      "12/08/2022 05:46:06 PM Epoch: 0 | Loss: 3.218\n",
      "12/08/2022 05:46:08 PM Epoch: 0 | Loss: 3.066\n",
      "12/08/2022 05:46:11 PM Epoch: 0 | Loss: 3.227\n",
      "12/08/2022 05:46:13 PM Epoch: 0 | Loss: 3.451\n",
      "12/08/2022 05:46:16 PM Epoch: 0 | Loss: 2.634\n",
      "12/08/2022 05:46:18 PM Epoch: 0 | Loss: 3.212\n",
      "12/08/2022 05:46:21 PM Epoch: 0 | Loss: 3.46\n",
      "12/08/2022 05:46:23 PM Epoch: 0 | Loss: 3.086\n",
      "12/08/2022 05:46:26 PM Epoch: 0 | Loss: 2.413\n",
      "12/08/2022 05:46:29 PM Epoch: 0 | Loss: 3.405\n",
      "12/08/2022 05:46:31 PM Epoch: 0 | Loss: 3.151\n",
      "12/08/2022 05:46:34 PM Epoch: 0 | Loss: 3.849\n",
      "12/08/2022 05:46:36 PM Epoch: 0 | Loss: 2.847\n",
      "12/08/2022 05:46:39 PM Epoch: 0 | Loss: 3.804\n",
      "12/08/2022 05:46:41 PM Epoch: 0 | Loss: 2.781\n",
      "12/08/2022 05:46:44 PM Epoch: 0 | Loss: 3.087\n",
      "12/08/2022 05:46:46 PM Epoch: 0 | Loss: 2.674\n",
      "12/08/2022 05:46:49 PM Epoch: 0 | Loss: 2.673\n",
      "12/08/2022 05:46:52 PM Epoch: 0 | Loss: 3.723\n",
      "12/08/2022 05:46:54 PM Epoch: 0 | Loss: 3.473\n",
      "12/08/2022 05:46:57 PM Epoch: 0 | Loss: 3.249\n",
      "12/08/2022 05:46:59 PM Epoch: 0 | Loss: 2.741\n",
      "12/08/2022 05:47:02 PM Epoch: 0 | Loss: 3.185\n",
      "12/08/2022 05:47:04 PM Epoch: 0 | Loss: 3.327\n",
      "12/08/2022 05:47:07 PM Epoch: 0 | Loss: 2.35\n",
      "12/08/2022 05:47:09 PM Epoch: 0 | Loss: 3.457\n",
      "12/08/2022 05:47:12 PM Epoch: 0 | Loss: 3.087\n",
      "12/08/2022 05:47:15 PM Epoch: 0 | Loss: 3.049\n",
      "12/08/2022 05:47:17 PM Epoch: 0 | Loss: 2.81\n",
      "12/08/2022 05:47:20 PM Epoch: 0 | Loss: 2.83\n",
      "12/08/2022 05:47:22 PM Epoch: 0 | Loss: 2.794\n",
      "12/08/2022 05:47:25 PM Epoch: 0 | Loss: 2.878\n",
      "12/08/2022 05:47:27 PM Epoch: 0 | Loss: 3.396\n",
      "12/08/2022 05:47:30 PM Epoch: 0 | Loss: 2.877\n",
      "12/08/2022 05:47:32 PM Epoch: 0 | Loss: 2.675\n",
      "12/08/2022 05:47:35 PM Epoch: 0 | Loss: 2.623\n",
      "12/08/2022 05:47:38 PM Epoch: 0 | Loss: 2.97\n",
      "12/08/2022 05:47:40 PM Epoch: 0 | Loss: 3.087\n",
      "12/08/2022 05:47:43 PM Epoch: 0 | Loss: 3.329\n",
      "12/08/2022 05:47:45 PM Epoch: 0 | Loss: 2.703\n",
      "12/08/2022 05:47:48 PM Epoch: 0 | Loss: 2.963\n",
      "12/08/2022 05:47:50 PM Epoch: 0 | Loss: 2.844\n",
      "12/08/2022 05:47:53 PM Epoch: 0 | Loss: 3.955\n",
      "12/08/2022 05:47:56 PM Epoch: 0 | Loss: 3.388\n",
      "12/08/2022 05:47:58 PM Epoch: 0 | Loss: 3.294\n",
      "12/08/2022 05:48:01 PM Epoch: 0 | Loss: 3.129\n",
      "12/08/2022 05:48:03 PM Epoch: 0 | Loss: 2.864\n",
      "12/08/2022 05:48:06 PM Epoch: 0 | Loss: 3.426\n",
      "12/08/2022 05:48:08 PM Epoch: 0 | Loss: 2.422\n",
      "12/08/2022 05:48:11 PM Epoch: 0 | Loss: 3.05\n",
      "12/08/2022 05:48:13 PM Epoch: 0 | Loss: 2.78\n",
      "12/08/2022 05:48:16 PM Epoch: 0 | Loss: 2.726\n",
      "12/08/2022 05:48:19 PM Epoch: 0 | Loss: 3.496\n",
      "12/08/2022 05:48:21 PM Epoch: 0 | Loss: 3.093\n",
      "12/08/2022 05:48:24 PM Epoch: 0 | Loss: 2.408\n",
      "12/08/2022 05:48:26 PM Epoch: 0 | Loss: 2.939\n",
      "12/08/2022 05:48:29 PM Epoch: 0 | Loss: 2.6\n",
      "12/08/2022 05:48:31 PM Epoch: 0 | Loss: 3.111\n",
      "12/08/2022 05:48:34 PM Epoch: 0 | Loss: 3.172\n",
      "12/08/2022 05:48:36 PM Epoch: 0 | Loss: 2.796\n",
      "12/08/2022 05:48:39 PM Epoch: 0 | Loss: 3.177\n",
      "12/08/2022 05:48:41 PM Epoch: 0 | Loss: 2.557\n",
      "12/08/2022 05:48:44 PM Epoch: 0 | Loss: 2.936\n",
      "12/08/2022 05:48:47 PM Epoch: 0 | Loss: 3.201\n",
      "12/08/2022 05:48:49 PM Epoch: 0 | Loss: 3.11\n",
      "12/08/2022 05:48:52 PM Epoch: 0 | Loss: 3.181\n",
      "12/08/2022 05:48:54 PM Epoch: 0 | Loss: 3.189\n",
      "12/08/2022 05:48:57 PM Epoch: 0 | Loss: 3.058\n",
      "12/08/2022 05:48:59 PM Epoch: 0 | Loss: 3.489\n",
      "12/08/2022 05:49:02 PM Epoch: 0 | Loss: 2.592\n",
      "12/08/2022 05:49:05 PM Epoch: 0 | Loss: 2.566\n",
      "12/08/2022 05:49:07 PM Epoch: 0 | Loss: 3.666\n",
      "12/08/2022 05:49:10 PM Epoch: 0 | Loss: 3.384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/08/2022 05:49:12 PM Epoch: 0 | Loss: 3.74\n",
      "12/08/2022 05:49:15 PM Epoch: 0 | Loss: 2.9\n",
      "12/08/2022 05:49:17 PM Epoch: 0 | Loss: 2.763\n",
      "12/08/2022 05:49:20 PM Epoch: 0 | Loss: 2.636\n",
      "12/08/2022 05:49:23 PM Epoch: 0 | Loss: 3.022\n",
      "12/08/2022 05:49:25 PM Epoch: 0 | Loss: 3.183\n",
      "12/08/2022 05:49:28 PM Epoch: 0 | Loss: 3.093\n",
      "12/08/2022 05:49:30 PM Epoch: 0 | Loss: 2.787\n",
      "12/08/2022 05:49:33 PM Epoch: 0 | Loss: 2.865\n",
      "12/08/2022 05:49:35 PM Epoch: 0 | Loss: 2.683\n",
      "12/08/2022 05:49:38 PM Epoch: 0 | Loss: 3.045\n",
      "12/08/2022 05:49:41 PM Epoch: 0 | Loss: 2.893\n",
      "12/08/2022 05:49:43 PM Epoch: 0 | Loss: 3.073\n",
      "12/08/2022 05:49:46 PM Epoch: 0 | Loss: 3.002\n",
      "12/08/2022 05:49:48 PM Epoch: 0 | Loss: 2.804\n",
      "12/08/2022 05:49:51 PM Epoch: 0 | Loss: 3.3\n",
      "12/08/2022 05:49:53 PM Epoch: 0 | Loss: 2.989\n",
      "12/08/2022 05:49:56 PM Epoch: 0 | Loss: 3.017\n",
      "12/08/2022 05:49:58 PM Epoch: 0 | Loss: 2.397\n",
      "12/08/2022 05:50:01 PM Epoch: 0 | Loss: 2.788\n",
      "12/08/2022 05:50:04 PM Epoch: 0 | Loss: 2.877\n",
      "12/08/2022 05:50:06 PM Epoch: 0 | Loss: 3.127\n",
      "12/08/2022 05:50:09 PM Epoch: 0 | Loss: 3.465\n",
      "12/08/2022 05:50:11 PM Epoch: 0 | Loss: 2.47\n",
      "12/08/2022 05:50:14 PM Epoch: 0 | Loss: 3.125\n",
      "12/08/2022 05:50:16 PM Epoch: 0 | Loss: 2.401\n",
      "12/08/2022 05:50:19 PM Epoch: 0 | Loss: 2.758\n",
      "12/08/2022 05:50:21 PM Epoch: 0 | Loss: 2.456\n",
      "12/08/2022 05:50:24 PM Epoch: 0 | Loss: 3.069\n",
      "12/08/2022 05:50:27 PM Epoch: 0 | Loss: 2.503\n",
      "12/08/2022 05:50:29 PM Epoch: 0 | Loss: 2.337\n",
      "12/08/2022 05:50:32 PM Epoch: 0 | Loss: 2.722\n",
      "12/08/2022 05:50:34 PM Epoch: 0 | Loss: 2.756\n",
      "12/08/2022 05:50:37 PM Epoch: 0 | Loss: 2.569\n",
      "12/08/2022 05:50:39 PM Epoch: 0 | Loss: 2.758\n",
      "12/08/2022 05:50:42 PM Epoch: 0 | Loss: 2.054\n",
      "12/08/2022 05:50:44 PM Epoch: 0 | Loss: 3.184\n",
      "12/08/2022 05:50:47 PM Epoch: 0 | Loss: 2.481\n",
      "12/08/2022 05:50:50 PM Epoch: 0 | Loss: 3.128\n",
      "12/08/2022 05:50:52 PM Epoch: 0 | Loss: 3.018\n",
      "12/08/2022 05:50:55 PM Epoch: 0 | Loss: 3.221\n",
      "12/08/2022 05:50:57 PM Epoch: 0 | Loss: 3.096\n",
      "12/08/2022 05:51:00 PM Epoch: 0 | Loss: 2.613\n",
      "12/08/2022 05:51:02 PM Epoch: 0 | Loss: 2.577\n",
      "12/08/2022 05:51:05 PM Epoch: 0 | Loss: 3.201\n",
      "12/08/2022 05:51:07 PM Epoch: 0 | Loss: 2.652\n",
      "12/08/2022 05:51:10 PM Epoch: 0 | Loss: 2.99\n",
      "12/08/2022 05:51:13 PM Epoch: 0 | Loss: 3.256\n",
      "12/08/2022 05:51:15 PM Epoch: 0 | Loss: 3.035\n",
      "12/08/2022 05:51:18 PM Epoch: 0 | Loss: 2.936\n",
      "12/08/2022 05:51:20 PM Epoch: 0 | Loss: 3.063\n",
      "12/08/2022 05:51:23 PM Epoch: 0 | Loss: 2.636\n",
      "12/08/2022 05:51:25 PM Epoch: 0 | Loss: 3.206\n",
      "12/08/2022 05:51:28 PM Epoch: 0 | Loss: 2.425\n",
      "12/08/2022 05:51:30 PM Epoch: 0 | Loss: 2.674\n",
      "12/08/2022 05:51:33 PM Epoch: 0 | Loss: 2.448\n",
      "12/08/2022 05:51:36 PM Epoch: 0 | Loss: 2.728\n",
      "12/08/2022 05:51:38 PM Epoch: 0 | Loss: 2.997\n",
      "12/08/2022 05:51:41 PM Epoch: 0 | Loss: 3.28\n",
      "12/08/2022 05:51:43 PM Epoch: 0 | Loss: 3.47\n",
      "12/08/2022 05:51:46 PM Epoch: 0 | Loss: 3.371\n",
      "12/08/2022 05:51:48 PM Epoch: 0 | Loss: 2.634\n",
      "12/08/2022 05:51:51 PM Epoch: 0 | Loss: 2.837\n",
      "12/08/2022 05:51:54 PM Epoch: 0 | Loss: 2.528\n",
      "12/08/2022 05:51:56 PM Epoch: 0 | Loss: 2.996\n",
      "12/08/2022 05:51:59 PM Epoch: 0 | Loss: 3.07\n",
      "12/08/2022 05:52:01 PM Epoch: 0 | Loss: 2.167\n",
      "12/08/2022 05:52:04 PM Epoch: 0 | Loss: 2.466\n",
      "12/08/2022 05:52:06 PM Epoch: 0 | Loss: 2.751\n",
      "12/08/2022 05:52:09 PM Epoch: 0 | Loss: 2.775\n",
      "12/08/2022 05:52:11 PM Epoch: 0 | Loss: 3.252\n",
      "12/08/2022 05:52:14 PM Epoch: 0 | Loss: 3.062\n",
      "12/08/2022 05:52:17 PM Epoch: 0 | Loss: 3.028\n",
      "12/08/2022 05:52:19 PM Epoch: 0 | Loss: 3.217\n",
      "12/08/2022 05:52:22 PM Epoch: 0 | Loss: 2.197\n",
      "12/08/2022 05:52:24 PM Epoch: 0 | Loss: 2.861\n",
      "12/08/2022 05:52:27 PM Epoch: 0 | Loss: 3.38\n",
      "12/08/2022 05:52:29 PM Epoch: 0 | Loss: 2.65\n",
      "12/08/2022 05:52:32 PM Epoch: 0 | Loss: 2.974\n",
      "12/08/2022 05:52:34 PM Epoch: 0 | Loss: 2.933\n",
      "12/08/2022 05:52:37 PM Epoch: 0 | Loss: 3.125\n",
      "12/08/2022 05:52:40 PM Epoch: 0 | Loss: 2.72\n",
      "12/08/2022 05:52:42 PM Epoch: 0 | Loss: 3.606\n",
      "12/08/2022 05:52:45 PM Epoch: 0 | Loss: 2.475\n",
      "12/08/2022 05:52:47 PM Epoch: 0 | Loss: 2.853\n",
      "12/08/2022 05:52:50 PM Epoch: 0 | Loss: 2.478\n",
      "12/08/2022 05:52:52 PM Epoch: 0 | Loss: 2.867\n",
      "12/08/2022 05:52:55 PM Epoch: 0 | Loss: 2.773\n",
      "12/08/2022 05:52:57 PM Epoch: 0 | Loss: 3.259\n",
      "12/08/2022 05:53:00 PM Epoch: 0 | Loss: 2.563\n",
      "12/08/2022 05:53:03 PM Epoch: 0 | Loss: 2.84\n",
      "12/08/2022 05:53:05 PM Epoch: 0 | Loss: 2.816\n",
      "12/08/2022 05:53:08 PM Epoch: 0 | Loss: 2.634\n",
      "12/08/2022 05:53:10 PM Epoch: 0 | Loss: 2.733\n",
      "12/08/2022 05:53:13 PM Epoch: 0 | Loss: 2.084\n",
      "12/08/2022 05:53:15 PM Epoch: 0 | Loss: 2.657\n",
      "12/08/2022 05:53:18 PM Epoch: 0 | Loss: 2.641\n",
      "12/08/2022 05:53:20 PM Epoch: 0 | Loss: 2.393\n",
      "12/08/2022 05:53:23 PM Epoch: 0 | Loss: 2.676\n",
      "12/08/2022 05:53:25 PM Epoch: 0 | Loss: 2.755\n",
      "12/08/2022 05:53:28 PM Epoch: 0 | Loss: 2.655\n",
      "12/08/2022 05:53:31 PM Epoch: 0 | Loss: 2.636\n",
      "12/08/2022 05:53:33 PM Epoch: 0 | Loss: 2.942\n",
      "12/08/2022 05:53:36 PM Epoch: 0 | Loss: 2.917\n",
      "12/08/2022 05:53:38 PM Epoch: 0 | Loss: 2.404\n",
      "12/08/2022 05:53:41 PM Epoch: 0 | Loss: 2.665\n",
      "12/08/2022 05:53:43 PM Epoch: 0 | Loss: 3.186\n",
      "12/08/2022 05:53:46 PM Epoch: 0 | Loss: 2.516\n",
      "12/08/2022 05:53:48 PM Epoch: 0 | Loss: 2.66\n",
      "12/08/2022 05:53:51 PM Epoch: 0 | Loss: 2.992\n",
      "12/08/2022 05:53:54 PM Epoch: 0 | Loss: 3.546\n",
      "12/08/2022 05:53:56 PM Epoch: 0 | Loss: 2.932\n",
      "12/08/2022 05:53:59 PM Epoch: 0 | Loss: 2.614\n",
      "12/08/2022 05:54:01 PM Epoch: 0 | Loss: 2.734\n",
      "12/08/2022 05:54:04 PM Epoch: 0 | Loss: 1.994\n",
      "12/08/2022 05:54:06 PM Epoch: 0 | Loss: 3.022\n",
      "12/08/2022 05:54:09 PM Epoch: 0 | Loss: 2.936\n",
      "12/08/2022 05:54:11 PM Epoch: 0 | Loss: 2.637\n",
      "12/08/2022 05:54:14 PM Epoch: 0 | Loss: 3.082\n",
      "12/08/2022 05:54:17 PM Epoch: 0 | Loss: 2.631\n",
      "12/08/2022 05:54:19 PM Epoch: 0 | Loss: 3.422\n",
      "12/08/2022 05:54:22 PM Epoch: 0 | Loss: 2.334\n",
      "12/08/2022 05:54:24 PM Epoch: 0 | Loss: 2.837\n",
      "12/08/2022 05:54:27 PM Epoch: 0 | Loss: 2.82\n",
      "12/08/2022 05:54:29 PM Epoch: 0 | Loss: 2.413\n",
      "12/08/2022 05:54:32 PM Epoch: 0 | Loss: 3.117\n",
      "12/08/2022 05:54:34 PM Epoch: 0 | Loss: 2.508\n",
      "12/08/2022 05:54:37 PM Epoch: 0 | Loss: 3.035\n",
      "12/08/2022 05:54:40 PM Epoch: 0 | Loss: 2.714\n",
      "12/08/2022 05:54:42 PM Epoch: 0 | Loss: 3.063\n",
      "12/08/2022 05:54:45 PM Epoch: 0 | Loss: 3.282\n",
      "12/08/2022 05:54:47 PM Epoch: 0 | Loss: 2.525\n",
      "12/08/2022 05:54:50 PM Epoch: 0 | Loss: 2.635\n",
      "12/08/2022 05:54:52 PM Epoch: 0 | Loss: 2.956\n",
      "12/08/2022 05:54:55 PM Epoch: 0 | Loss: 2.767\n",
      "12/08/2022 05:54:57 PM Epoch: 0 | Loss: 2.31\n",
      "12/08/2022 05:55:00 PM Epoch: 0 | Loss: 2.733\n",
      "12/08/2022 05:55:02 PM Epoch: 0 | Loss: 1.989\n",
      "12/08/2022 05:55:05 PM Epoch: 0 | Loss: 2.983\n",
      "12/08/2022 05:55:08 PM Epoch: 0 | Loss: 2.963\n",
      "12/08/2022 05:55:10 PM Epoch: 0 | Loss: 2.637\n",
      "12/08/2022 05:55:13 PM Epoch: 0 | Loss: 2.234\n",
      "12/08/2022 05:55:15 PM Epoch: 0 | Loss: 3.324\n",
      "12/08/2022 05:55:18 PM Epoch: 0 | Loss: 2.67\n",
      "12/08/2022 05:55:20 PM Epoch: 0 | Loss: 3.172\n",
      "12/08/2022 05:55:23 PM Epoch: 0 | Loss: 3.166\n",
      "12/08/2022 05:55:26 PM Epoch: 0 | Loss: 2.74\n",
      "12/08/2022 05:55:28 PM Epoch: 0 | Loss: 3.021\n",
      "12/08/2022 05:55:31 PM Epoch: 0 | Loss: 2.851\n",
      "12/08/2022 05:55:33 PM Epoch: 0 | Loss: 2.395\n",
      "12/08/2022 05:55:36 PM Epoch: 0 | Loss: 2.59\n",
      "12/08/2022 05:55:38 PM Epoch: 0 | Loss: 3.426\n",
      "12/08/2022 05:55:41 PM Epoch: 0 | Loss: 3.099\n",
      "12/08/2022 05:55:43 PM Epoch: 0 | Loss: 2.68\n",
      "12/08/2022 05:55:46 PM Epoch: 0 | Loss: 3.624\n",
      "12/08/2022 05:55:49 PM Epoch: 0 | Loss: 2.619\n",
      "12/08/2022 05:55:51 PM Epoch: 0 | Loss: 3.141\n",
      "12/08/2022 05:55:54 PM Epoch: 0 | Loss: 2.732\n",
      "12/08/2022 05:55:56 PM Epoch: 0 | Loss: 2.464\n",
      "12/08/2022 05:55:59 PM Epoch: 0 | Loss: 2.866\n",
      "12/08/2022 05:56:01 PM Epoch: 0 | Loss: 2.558\n",
      "12/08/2022 05:56:04 PM Epoch: 0 | Loss: 2.83\n",
      "12/08/2022 05:56:06 PM Epoch: 0 | Loss: 2.837\n",
      "12/08/2022 05:56:09 PM Epoch: 0 | Loss: 2.957\n",
      "12/08/2022 05:56:12 PM Epoch: 0 | Loss: 2.815\n",
      "12/08/2022 05:56:14 PM Epoch: 0 | Loss: 3.003\n",
      "12/08/2022 05:56:17 PM Epoch: 0 | Loss: 2.732\n",
      "12/08/2022 05:56:19 PM Epoch: 0 | Loss: 2.594\n",
      "12/08/2022 05:56:22 PM Epoch: 0 | Loss: 3.401\n",
      "12/08/2022 05:56:24 PM Epoch: 0 | Loss: 2.685\n",
      "12/08/2022 05:56:27 PM Epoch: 0 | Loss: 2.824\n",
      "12/08/2022 05:56:29 PM Epoch: 0 | Loss: 2.604\n",
      "12/08/2022 05:56:32 PM Epoch: 0 | Loss: 2.593\n",
      "12/08/2022 05:56:35 PM Epoch: 0 | Loss: 2.961\n",
      "12/08/2022 05:56:37 PM Epoch: 0 | Loss: 2.46\n",
      "12/08/2022 05:56:40 PM Epoch: 0 | Loss: 2.502\n",
      "12/08/2022 05:56:42 PM Epoch: 0 | Loss: 3.056\n",
      "12/08/2022 05:56:45 PM Epoch: 0 | Loss: 3.202\n",
      "12/08/2022 05:56:47 PM Epoch: 0 | Loss: 2.232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/08/2022 05:56:50 PM Epoch: 0 | Loss: 2.671\n",
      "12/08/2022 05:56:52 PM Epoch: 0 | Loss: 2.688\n"
     ]
    }
   ],
   "source": [
    "mT5Trainer(dataframe=df, source_text=\"text\", target_text=\"title\", model_params=model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b30e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams_model = torch.load(\"./outputs/model_files/pytorch_model.bin\")\n",
    "config = MT5Config.from_pretrained(model_params['MODEL'])\n",
    "trained_model = MT5ForConditionalGeneration.from_pretrained(\"./outputs/model_files/pytorch_model.bin\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cca0fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "\"La entrega de los premios Musa del domingo pasado habría generado un conflicto que involucra a artistas urbanos como AK4:20, Pailita y Polimá. En la ceremonia, Pailita ganó como Mejor Artista Urbano y junto a Polimá ganaron Mejor Colaboración y Canción del Año por \"Ultra Solo\". Mientras Young Cister también se llevó dos galardones.Sin embargo, en Instagram reportaron que el equipo de AK4:20 tuvo duras palabras para los premios Musa. \"Su premios 'kls' son 'si me das algo te nomino'. Son entero falsos programas 'ktm'\", escribieron en el equipo del hombre de \"Rata tan tan\", terminando con \"Telebasura\". Mientras tanto, el manager del artista Bayron Fire también subió una historia con el texto: \"Premios Musa son más chanta que la ropa de La Polar\". Otro que escribió fue Balbi El Chamako, que entre otras cosas afirmó que \"por culpa de los apitutados o 'wnes' cuicos que tienen cantando a sus regalones (...) ocupan espacios que se los merecían los que de verdad sí lucharon\" y que \"la mafia detrás del género, la desigualdad y el clasismo siempre nos dividirán\". Por su parte, Pailita solo subió un escueto mensaje en su Instagram que dice: \"Si un compañero mío gana, yo también gano. Lo felicito y me alegro por él. Esa es la hermandad\".\"\"\"\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_params['MODEL'])\n",
    "input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    " \n",
    "generated_ids = trained_model.generate(input_ids, do_sample=True, \n",
    "    max_length=50, \n",
    "    top_k=0, \n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "summary = tokenizer.decode(generated_ids.squeeze(), skip_special_tokens=True)\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
